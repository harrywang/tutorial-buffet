{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA for news headlines\n",
    "\n",
    "My revised code for \n",
    "\n",
    "- https://github.com/susanli2016/NLP-with-Python/blob/master/LDA_news_headlines.ipynb\n",
    "- https://towardsdatascience.com/topic-modeling-and-latent-dirichlet-allocation-in-python-9bf156893c24\n",
    "\n",
    "\n",
    "\n",
    "`abcnews-small.csv` is a ~10k subset of the original 1 million dataset that can be downloaded at https://www.kaggle.com/therohk/million-headlines, which is about 60m unzipped. \n",
    "\n",
    "Running the whole dataset on a 2017 MacBook Pro:\n",
    "\n",
    "- the preprocessing step is about 3 minutes: `processed_docs = documents['headline_text'].map(preprocess)`\n",
    "- the training step using bag of words is about 5min 46s: `lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)`\n",
    "- the training step using tf-idf is about 9min 21s: `lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# uncomment the following line if you want to try the full dataset\n",
    "#data = pd.read_csv('data/abcnews-date-text.csv', error_bad_lines=False);\n",
    "\n",
    "# read a subset of the full dataset\n",
    "data = pd.read_csv('data/abcnews-small.csv', error_bad_lines=False);\n",
    "\n",
    "data_text = data[['headline_text']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "10001"
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "                                    headline_text  index\n0  report highlights container terminal potential      0\n1                   mud crab business on the move      1\n2             sporting task force planning begins      2\n3               ama airs hospital reform concerns      3\n4    health service speaks out over patient death      4",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>headline_text</th>\n      <th>index</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>report highlights container terminal potential</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>mud crab business on the move</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>sporting task force planning begins</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ama airs hospital reform concerns</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>health service speaks out over patient death</td>\n      <td>4</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[nltk_data] Downloading package wordnet to\n[nltk_data]     /Users/harrywang/nltk_data...\n[nltk_data]   Package wordnet is already up-to-date!\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "True"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "go\n"
    }
   ],
   "source": [
    "print(WordNetLemmatizer().lemmatize('went', pos='v'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stemmer Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   original word stemmed\n0       caresses  caress\n1          flies     fli\n2           dies     die\n3          mules    mule\n4         denied    deni\n5           died     die\n6         agreed    agre\n7          owned     own\n8        humbled   humbl\n9          sized    size\n10       meeting    meet\n11       stating   state\n12       siezing    siez\n13   itemization    item\n14   sensational  sensat\n15   traditional  tradit\n16     reference   refer\n17     colonizer   colon\n18       plotted    plot",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>original word</th>\n      <th>stemmed</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>caresses</td>\n      <td>caress</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>flies</td>\n      <td>fli</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>dies</td>\n      <td>die</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>mules</td>\n      <td>mule</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>denied</td>\n      <td>deni</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>died</td>\n      <td>die</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>agreed</td>\n      <td>agre</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>owned</td>\n      <td>own</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>humbled</td>\n      <td>humbl</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>sized</td>\n      <td>size</td>\n    </tr>\n    <tr>\n      <th>10</th>\n      <td>meeting</td>\n      <td>meet</td>\n    </tr>\n    <tr>\n      <th>11</th>\n      <td>stating</td>\n      <td>state</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>siezing</td>\n      <td>siez</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>itemization</td>\n      <td>item</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>sensational</td>\n      <td>sensat</td>\n    </tr>\n    <tr>\n      <th>15</th>\n      <td>traditional</td>\n      <td>tradit</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>reference</td>\n      <td>refer</td>\n    </tr>\n    <tr>\n      <th>17</th>\n      <td>colonizer</td>\n      <td>colon</td>\n    </tr>\n    <tr>\n      <th>18</th>\n      <td>plotted</td>\n      <td>plot</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "stemmer = SnowballStemmer('english')\n",
    "original_words = ['caresses', 'flies', 'dies', 'mules', 'denied','died', 'agreed', 'owned', \n",
    "           'humbled', 'sized','meeting', 'stating', 'siezing', 'itemization','sensational', \n",
    "           'traditional', 'reference', 'colonizer','plotted']\n",
    "singles = [stemmer.stem(plural) for plural in original_words]\n",
    "pd.DataFrame(data = {'original word': original_words, 'stemmed': singles})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in gensim.parsing.preprocessing.STOPWORDS and len(token) > 3:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "original document: \n[&#39;charity&#39;, &#39;in&#39;, &#39;demand&#39;, &#39;from&#39;, &#39;sacked&#39;, &#39;meatworkers&#39;]\n\n\n tokenized and lemmatized document: \n[&#39;chariti&#39;, &#39;demand&#39;, &#39;sack&#39;, &#39;meatwork&#39;]\n"
    }
   ],
   "source": [
    "doc_sample = documents[documents['index'] == 4310].values[0][0]\n",
    "\n",
    "print('original document: ')\n",
    "words = []\n",
    "for word in doc_sample.split(' '):\n",
    "    words.append(word)\n",
    "print(words)\n",
    "print('\\n\\n tokenized and lemmatized document: ')\n",
    "print(preprocess(doc_sample))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 1.58 s, sys: 107 ms, total: 1.69 s\nWall time: 2.65 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "# for the 1 million dataset, wall time: 2min 59s\n",
    "processed_docs = documents['headline_text'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0    [report, highlight, contain, termin, potenti]\n1                                     [crab, busi]\n2                 [sport, task, forc, plan, begin]\n3                   [air, hospit, reform, concern]\n4          [health, servic, speak, patient, death]\n5                              [hors, ride, enact]\n6                 [plan, intersect, revamp, begin]\n7                      [stormer, slaughter, shark]\n8               [england, deserv, favourit, oneil]\n9      [firefight, continu, contain, effort, near]\nName: headline_text, dtype: object"
     },
     "metadata": {},
     "execution_count": 54
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "0 contain\n1 highlight\n2 potenti\n3 report\n4 termin\n5 busi\n6 crab\n7 begin\n8 forc\n9 plan\n10 sport\n"
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[(277, 1), (435, 1)]"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Word 277 (&quot;demand&quot;) appears 1 time.\nWord 435 (&quot;sack&quot;) appears 1 time.\n"
    }
   ],
   "source": [
    "bow_doc_4310 = bow_corpus[4310]\n",
    "\n",
    "for i in range(len(bow_doc_4310)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_4310[i][0], \n",
    "                                                     dictionary[bow_doc_4310[i][0]], \n",
    "                                                     bow_doc_4310[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[(0, 0.802436033281265), (1, 0.5967381439893285)]\n"
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 2.22 s, sys: 631 ms, total: 2.85 s\nWall time: 5.83 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=10, id2word=dictionary, passes=2, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Topic: 0 \nWords: 0.037*&quot;interview&quot; + 0.035*&quot;polic&quot; + 0.020*&quot;home&quot; + 0.015*&quot;hous&quot; + 0.014*&quot;school&quot; + 0.013*&quot;brisban&quot; + 0.012*&quot;question&quot; + 0.011*&quot;plead&quot; + 0.010*&quot;mark&quot; + 0.010*&quot;sydney&quot;\nTopic: 1 \nWords: 0.022*&quot;kill&quot; + 0.020*&quot;protest&quot; + 0.019*&quot;polic&quot; + 0.019*&quot;chang&quot; + 0.015*&quot;budget&quot; + 0.014*&quot;trump&quot; + 0.013*&quot;island&quot; + 0.013*&quot;tasmanian&quot; + 0.013*&quot;speak&quot; + 0.011*&quot;urg&quot;\nTopic: 2 \nWords: 0.040*&quot;australia&quot; + 0.026*&quot;year&quot; + 0.019*&quot;elect&quot; + 0.016*&quot;servic&quot; + 0.015*&quot;bank&quot; + 0.014*&quot;council&quot; + 0.013*&quot;miss&quot; + 0.012*&quot;vote&quot; + 0.012*&quot;plan&quot; + 0.011*&quot;high&quot;\nTopic: 3 \nWords: 0.013*&quot;plan&quot; + 0.013*&quot;govern&quot; + 0.013*&quot;court&quot; + 0.013*&quot;farmer&quot; + 0.012*&quot;public&quot; + 0.012*&quot;turnbul&quot; + 0.012*&quot;million&quot; + 0.011*&quot;campaign&quot; + 0.011*&quot;hospit&quot; + 0.011*&quot;climat&quot;\nTopic: 4 \nWords: 0.022*&quot;open&quot; + 0.013*&quot;elect&quot; + 0.013*&quot;local&quot; + 0.012*&quot;make&quot; + 0.012*&quot;trump&quot; + 0.012*&quot;adelaid&quot; + 0.012*&quot;plan&quot; + 0.012*&quot;donald&quot; + 0.011*&quot;defend&quot; + 0.011*&quot;report&quot;\nTopic: 5 \nWords: 0.020*&quot;work&quot; + 0.017*&quot;talk&quot; + 0.016*&quot;melbourn&quot; + 0.015*&quot;help&quot; + 0.015*&quot;arrest&quot; + 0.014*&quot;drug&quot; + 0.013*&quot;australian&quot; + 0.013*&quot;win&quot; + 0.013*&quot;market&quot; + 0.012*&quot;countri&quot;\nTopic: 6 \nWords: 0.018*&quot;dead&quot; + 0.013*&quot;go&quot; + 0.013*&quot;claim&quot; + 0.013*&quot;lose&quot; + 0.011*&quot;industri&quot; + 0.010*&quot;crash&quot; + 0.010*&quot;award&quot; + 0.009*&quot;region&quot; + 0.009*&quot;jail&quot; + 0.009*&quot;rule&quot;\nTopic: 7 \nWords: 0.027*&quot;say&quot; + 0.019*&quot;polic&quot; + 0.017*&quot;death&quot; + 0.015*&quot;group&quot; + 0.014*&quot;australia&quot; + 0.014*&quot;charg&quot; + 0.013*&quot;court&quot; + 0.013*&quot;govern&quot; + 0.012*&quot;world&quot; + 0.011*&quot;farm&quot;\nTopic: 8 \nWords: 0.037*&quot;say&quot; + 0.026*&quot;attack&quot; + 0.016*&quot;crash&quot; + 0.015*&quot;health&quot; + 0.014*&quot;state&quot; + 0.012*&quot;call&quot; + 0.012*&quot;face&quot; + 0.012*&quot;woman&quot; + 0.011*&quot;report&quot; + 0.011*&quot;coast&quot;\nTopic: 9 \nWords: 0.027*&quot;charg&quot; + 0.022*&quot;australian&quot; + 0.019*&quot;warn&quot; + 0.018*&quot;face&quot; + 0.017*&quot;polic&quot; + 0.014*&quot;return&quot; + 0.013*&quot;sydney&quot; + 0.012*&quot;world&quot; + 0.012*&quot;centr&quot; + 0.012*&quot;final&quot;\n"
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Can you distinguish different topics using the words in each topic and their corresponding weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "CPU times: user 1.81 s, sys: 341 ms, total: 2.15 s\nWall time: 4.6 s\n"
    }
   ],
   "source": [
    "%%time\n",
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=10, id2word=dictionary, passes=2, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Topic: 0 Word: 0.020*&quot;win&quot; + 0.017*&quot;australian&quot; + 0.017*&quot;tasmania&quot; + 0.015*&quot;test&quot; + 0.013*&quot;research&quot; + 0.013*&quot;look&quot; + 0.012*&quot;cricket&quot; + 0.011*&quot;launch&quot; + 0.010*&quot;port&quot; + 0.010*&quot;food&quot;\nTopic: 1 Word: 0.026*&quot;interview&quot; + 0.020*&quot;say&quot; + 0.019*&quot;woman&quot; + 0.016*&quot;charg&quot; + 0.015*&quot;final&quot; + 0.012*&quot;go&quot; + 0.012*&quot;perth&quot; + 0.009*&quot;polic&quot; + 0.009*&quot;australian&quot; + 0.008*&quot;indigen&quot;\nTopic: 2 Word: 0.019*&quot;say&quot; + 0.016*&quot;market&quot; + 0.016*&quot;polic&quot; + 0.014*&quot;time&quot; + 0.013*&quot;news&quot; + 0.012*&quot;brisban&quot; + 0.011*&quot;work&quot; + 0.011*&quot;melbourn&quot; + 0.011*&quot;monday&quot; + 0.010*&quot;report&quot;\nTopic: 3 Word: 0.021*&quot;elect&quot; + 0.017*&quot;miss&quot; + 0.016*&quot;plan&quot; + 0.012*&quot;talk&quot; + 0.012*&quot;centr&quot; + 0.012*&quot;leader&quot; + 0.011*&quot;aborigin&quot; + 0.010*&quot;violenc&quot; + 0.010*&quot;white&quot; + 0.010*&quot;sydney&quot;\nTopic: 4 Word: 0.024*&quot;interview&quot; + 0.020*&quot;kill&quot; + 0.014*&quot;attack&quot; + 0.013*&quot;coast&quot; + 0.012*&quot;power&quot; + 0.011*&quot;releas&quot; + 0.011*&quot;say&quot; + 0.010*&quot;peopl&quot; + 0.010*&quot;action&quot; + 0.009*&quot;step&quot;\nTopic: 5 Word: 0.017*&quot;school&quot; + 0.015*&quot;stand&quot; + 0.014*&quot;hour&quot; + 0.013*&quot;trial&quot; + 0.013*&quot;fiji&quot; + 0.012*&quot;court&quot; + 0.012*&quot;open&quot; + 0.011*&quot;accus&quot; + 0.011*&quot;countri&quot; + 0.011*&quot;murder&quot;\nTopic: 6 Word: 0.019*&quot;crash&quot; + 0.016*&quot;world&quot; + 0.012*&quot;adelaid&quot; + 0.011*&quot;record&quot; + 0.011*&quot;farm&quot; + 0.010*&quot;chines&quot; + 0.010*&quot;north&quot; + 0.009*&quot;queensland&quot; + 0.009*&quot;canberra&quot; + 0.009*&quot;discuss&quot;\nTopic: 7 Word: 0.018*&quot;govern&quot; + 0.016*&quot;want&quot; + 0.012*&quot;group&quot; + 0.012*&quot;child&quot; + 0.010*&quot;fund&quot; + 0.010*&quot;abus&quot; + 0.010*&quot;train&quot; + 0.010*&quot;sentenc&quot; + 0.010*&quot;year&quot; + 0.009*&quot;call&quot;\nTopic: 8 Word: 0.025*&quot;australia&quot; + 0.016*&quot;warn&quot; + 0.014*&quot;farmer&quot; + 0.012*&quot;court&quot; + 0.012*&quot;announc&quot; + 0.012*&quot;law&quot; + 0.011*&quot;open&quot; + 0.010*&quot;land&quot; + 0.010*&quot;lead&quot; + 0.010*&quot;tasmanian&quot;\nTopic: 9 Word: 0.020*&quot;trump&quot; + 0.018*&quot;death&quot; + 0.011*&quot;make&quot; + 0.011*&quot;hospit&quot; + 0.011*&quot;australian&quot; + 0.010*&quot;donald&quot; + 0.010*&quot;perth&quot; + 0.010*&quot;tuesday&quot; + 0.009*&quot;water&quot; + 0.009*&quot;royal&quot;\n"
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "[&#39;chariti&#39;, &#39;demand&#39;, &#39;sack&#39;, &#39;meatwork&#39;]"
     },
     "metadata": {},
     "execution_count": 67
    }
   ],
   "source": [
    "processed_docs[4310]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nScore: 0.6999604105949402\t \nTopic: 0.018*&quot;dead&quot; + 0.013*&quot;go&quot; + 0.013*&quot;claim&quot; + 0.013*&quot;lose&quot; + 0.011*&quot;industri&quot; + 0.010*&quot;crash&quot; + 0.010*&quot;award&quot; + 0.009*&quot;region&quot; + 0.009*&quot;jail&quot; + 0.009*&quot;rule&quot;\n\nScore: 0.033347394317388535\t \nTopic: 0.013*&quot;plan&quot; + 0.013*&quot;govern&quot; + 0.013*&quot;court&quot; + 0.013*&quot;farmer&quot; + 0.012*&quot;public&quot; + 0.012*&quot;turnbul&quot; + 0.012*&quot;million&quot; + 0.011*&quot;campaign&quot; + 0.011*&quot;hospit&quot; + 0.011*&quot;climat&quot;\n\nScore: 0.03334241360425949\t \nTopic: 0.040*&quot;australia&quot; + 0.026*&quot;year&quot; + 0.019*&quot;elect&quot; + 0.016*&quot;servic&quot; + 0.015*&quot;bank&quot; + 0.014*&quot;council&quot; + 0.013*&quot;miss&quot; + 0.012*&quot;vote&quot; + 0.012*&quot;plan&quot; + 0.011*&quot;high&quot;\n\nScore: 0.033337824046611786\t \nTopic: 0.037*&quot;say&quot; + 0.026*&quot;attack&quot; + 0.016*&quot;crash&quot; + 0.015*&quot;health&quot; + 0.014*&quot;state&quot; + 0.012*&quot;call&quot; + 0.012*&quot;face&quot; + 0.012*&quot;woman&quot; + 0.011*&quot;report&quot; + 0.011*&quot;coast&quot;\n\nScore: 0.03333580866456032\t \nTopic: 0.022*&quot;open&quot; + 0.013*&quot;elect&quot; + 0.013*&quot;local&quot; + 0.012*&quot;make&quot; + 0.012*&quot;trump&quot; + 0.012*&quot;adelaid&quot; + 0.012*&quot;plan&quot; + 0.012*&quot;donald&quot; + 0.011*&quot;defend&quot; + 0.011*&quot;report&quot;\n\nScore: 0.033335328102111816\t \nTopic: 0.027*&quot;charg&quot; + 0.022*&quot;australian&quot; + 0.019*&quot;warn&quot; + 0.018*&quot;face&quot; + 0.017*&quot;polic&quot; + 0.014*&quot;return&quot; + 0.013*&quot;sydney&quot; + 0.012*&quot;world&quot; + 0.012*&quot;centr&quot; + 0.012*&quot;final&quot;\n\nScore: 0.03333524614572525\t \nTopic: 0.027*&quot;say&quot; + 0.019*&quot;polic&quot; + 0.017*&quot;death&quot; + 0.015*&quot;group&quot; + 0.014*&quot;australia&quot; + 0.014*&quot;charg&quot; + 0.013*&quot;court&quot; + 0.013*&quot;govern&quot; + 0.012*&quot;world&quot; + 0.011*&quot;farm&quot;\n\nScore: 0.033335208892822266\t \nTopic: 0.020*&quot;work&quot; + 0.017*&quot;talk&quot; + 0.016*&quot;melbourn&quot; + 0.015*&quot;help&quot; + 0.015*&quot;arrest&quot; + 0.014*&quot;drug&quot; + 0.013*&quot;australian&quot; + 0.013*&quot;win&quot; + 0.013*&quot;market&quot; + 0.012*&quot;countri&quot;\n\nScore: 0.03333519399166107\t \nTopic: 0.037*&quot;interview&quot; + 0.035*&quot;polic&quot; + 0.020*&quot;home&quot; + 0.015*&quot;hous&quot; + 0.014*&quot;school&quot; + 0.013*&quot;brisban&quot; + 0.012*&quot;question&quot; + 0.011*&quot;plead&quot; + 0.010*&quot;mark&quot; + 0.010*&quot;sydney&quot;\n\nScore: 0.03333517909049988\t \nTopic: 0.022*&quot;kill&quot; + 0.020*&quot;protest&quot; + 0.019*&quot;polic&quot; + 0.019*&quot;chang&quot; + 0.015*&quot;budget&quot; + 0.014*&quot;trump&quot; + 0.013*&quot;island&quot; + 0.013*&quot;tasmanian&quot; + 0.013*&quot;speak&quot; + 0.011*&quot;urg&quot;\n"
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic on the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation by classifying sample document using LDA TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "\nScore: 0.6999433040618896\t \nTopic: 0.024*&quot;interview&quot; + 0.020*&quot;kill&quot; + 0.014*&quot;attack&quot; + 0.013*&quot;coast&quot; + 0.012*&quot;power&quot; + 0.011*&quot;releas&quot; + 0.011*&quot;say&quot; + 0.010*&quot;peopl&quot; + 0.010*&quot;action&quot; + 0.009*&quot;step&quot;\n\nScore: 0.0333525687456131\t \nTopic: 0.018*&quot;govern&quot; + 0.016*&quot;want&quot; + 0.012*&quot;group&quot; + 0.012*&quot;child&quot; + 0.010*&quot;fund&quot; + 0.010*&quot;abus&quot; + 0.010*&quot;train&quot; + 0.010*&quot;sentenc&quot; + 0.010*&quot;year&quot; + 0.009*&quot;call&quot;\n\nScore: 0.03334299474954605\t \nTopic: 0.026*&quot;interview&quot; + 0.020*&quot;say&quot; + 0.019*&quot;woman&quot; + 0.016*&quot;charg&quot; + 0.015*&quot;final&quot; + 0.012*&quot;go&quot; + 0.012*&quot;perth&quot; + 0.009*&quot;polic&quot; + 0.009*&quot;australian&quot; + 0.008*&quot;indigen&quot;\n\nScore: 0.033339973539114\t \nTopic: 0.020*&quot;trump&quot; + 0.018*&quot;death&quot; + 0.011*&quot;make&quot; + 0.011*&quot;hospit&quot; + 0.011*&quot;australian&quot; + 0.010*&quot;donald&quot; + 0.010*&quot;perth&quot; + 0.010*&quot;tuesday&quot; + 0.009*&quot;water&quot; + 0.009*&quot;royal&quot;\n\nScore: 0.033338554203510284\t \nTopic: 0.019*&quot;crash&quot; + 0.016*&quot;world&quot; + 0.012*&quot;adelaid&quot; + 0.011*&quot;record&quot; + 0.011*&quot;farm&quot; + 0.010*&quot;chines&quot; + 0.010*&quot;north&quot; + 0.009*&quot;queensland&quot; + 0.009*&quot;canberra&quot; + 0.009*&quot;discuss&quot;\n\nScore: 0.033337488770484924\t \nTopic: 0.017*&quot;school&quot; + 0.015*&quot;stand&quot; + 0.014*&quot;hour&quot; + 0.013*&quot;trial&quot; + 0.013*&quot;fiji&quot; + 0.012*&quot;court&quot; + 0.012*&quot;open&quot; + 0.011*&quot;accus&quot; + 0.011*&quot;countri&quot; + 0.011*&quot;murder&quot;\n\nScore: 0.03333703428506851\t \nTopic: 0.019*&quot;say&quot; + 0.016*&quot;market&quot; + 0.016*&quot;polic&quot; + 0.014*&quot;time&quot; + 0.013*&quot;news&quot; + 0.012*&quot;brisban&quot; + 0.011*&quot;work&quot; + 0.011*&quot;melbourn&quot; + 0.011*&quot;monday&quot; + 0.010*&quot;report&quot;\n\nScore: 0.0333360955119133\t \nTopic: 0.020*&quot;win&quot; + 0.017*&quot;australian&quot; + 0.017*&quot;tasmania&quot; + 0.015*&quot;test&quot; + 0.013*&quot;research&quot; + 0.013*&quot;look&quot; + 0.012*&quot;cricket&quot; + 0.011*&quot;launch&quot; + 0.010*&quot;port&quot; + 0.010*&quot;food&quot;\n\nScore: 0.033336006104946136\t \nTopic: 0.025*&quot;australia&quot; + 0.016*&quot;warn&quot; + 0.014*&quot;farmer&quot; + 0.012*&quot;court&quot; + 0.012*&quot;announc&quot; + 0.012*&quot;law&quot; + 0.011*&quot;open&quot; + 0.010*&quot;land&quot; + 0.010*&quot;lead&quot; + 0.010*&quot;tasmanian&quot;\n\nScore: 0.03333596512675285\t \nTopic: 0.021*&quot;elect&quot; + 0.017*&quot;miss&quot; + 0.016*&quot;plan&quot; + 0.012*&quot;talk&quot; + 0.012*&quot;centr&quot; + 0.012*&quot;leader&quot; + 0.011*&quot;aborigin&quot; + 0.010*&quot;violenc&quot; + 0.010*&quot;white&quot; + 0.010*&quot;sydney&quot;\n"
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[4310]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic on the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Score: 0.6999323964118958\t Topic: 0.020*&quot;work&quot; + 0.017*&quot;talk&quot; + 0.016*&quot;melbourn&quot; + 0.015*&quot;help&quot; + 0.015*&quot;arrest&quot;\nScore: 0.03335041552782059\t Topic: 0.013*&quot;plan&quot; + 0.013*&quot;govern&quot; + 0.013*&quot;court&quot; + 0.013*&quot;farmer&quot; + 0.012*&quot;public&quot;\nScore: 0.03334531560540199\t Topic: 0.037*&quot;say&quot; + 0.026*&quot;attack&quot; + 0.016*&quot;crash&quot; + 0.015*&quot;health&quot; + 0.014*&quot;state&quot;\nScore: 0.0333448089659214\t Topic: 0.040*&quot;australia&quot; + 0.026*&quot;year&quot; + 0.019*&quot;elect&quot; + 0.016*&quot;servic&quot; + 0.015*&quot;bank&quot;\nScore: 0.033340469002723694\t Topic: 0.022*&quot;open&quot; + 0.013*&quot;elect&quot; + 0.013*&quot;local&quot; + 0.012*&quot;make&quot; + 0.012*&quot;trump&quot;\nScore: 0.03334016725420952\t Topic: 0.027*&quot;charg&quot; + 0.022*&quot;australian&quot; + 0.019*&quot;warn&quot; + 0.018*&quot;face&quot; + 0.017*&quot;polic&quot;\nScore: 0.0333387665450573\t Topic: 0.018*&quot;dead&quot; + 0.013*&quot;go&quot; + 0.013*&quot;claim&quot; + 0.013*&quot;lose&quot; + 0.011*&quot;industri&quot;\nScore: 0.03333800658583641\t Topic: 0.027*&quot;say&quot; + 0.019*&quot;polic&quot; + 0.017*&quot;death&quot; + 0.015*&quot;group&quot; + 0.014*&quot;australia&quot;\nScore: 0.03333493694663048\t Topic: 0.037*&quot;interview&quot; + 0.035*&quot;polic&quot; + 0.020*&quot;home&quot; + 0.015*&quot;hous&quot; + 0.014*&quot;school&quot;\nScore: 0.03333476185798645\t Topic: 0.022*&quot;kill&quot; + 0.020*&quot;protest&quot; + 0.019*&quot;polic&quot; + 0.019*&quot;chang&quot; + 0.015*&quot;budget&quot;\n"
    }
   ],
   "source": [
    "unseen_document = 'How a Pentagon deal became an identity crisis for Google'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# random choose 10,000 about 1/100 from the whole dataset\n",
    "import random\n",
    "\n",
    "# no need to run this, skip by default\n",
    "skip = True\n",
    "\n",
    "if not skip:\n",
    "    n = 1186018 # 1 million total \n",
    "    s = 10000 # random 10k\n",
    "    skip = sorted(random.sample(range(n), n-s))\n",
    "    data_small = pd.read_csv('data/abcnews-date-text.csv', skiprows=skip, error_bad_lines=False, names=['index', 'headline_text'])\n",
    "    data_small.drop('index', axis=1, inplace=True)\n",
    "    data_small.to_csv('data/abcnews-small.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('venv': venv)",
   "display_name": "Python 3.8.5 64-bit ('venv': venv)",
   "metadata": {
    "interpreter": {
     "hash": "163bc59d277bb55c8d64a0829d30debe134c86792423b3536594fd3c824a859f"
    }
   }
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}